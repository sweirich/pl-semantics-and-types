
@PhdThesis{ahmed:phd,
  author =       {Amal Ahmed},
  title =        {Semantics of Types for Mutable State},
  school =       {Princeton University},
  year =         2004}

@article{appel:steps,
author = {Appel, Andrew W. and McAllester, David},
title = {An indexed model of recursive types for foundational proof-carrying code},
year = {2001},
issue_date = {September 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/504709.504712},
doi = {10.1145/504709.504712},
abstract = {The proofs of "traditional" proof carrying code (PCC) are type-specialized in the sense that they require axioms about a specific type system. In contrast, the proofs of foundational PCC explicitly define all required types and explicitly prove all the required properties of those types assuming only a fixed foundation of mathematics such as higher-order logic. Foundational PCC is both more flexible and more secure than type-specialized PCC.For foundational PCC we need semantic models of type systems on von Neumann machines. Previous models have been either too weak (lacking general recursive types and first-class function-pointers), too complex (requiring machine-checkable proofs of large bodies of computability theory), or not obviously applicable to von Neumann machines. Our new model is strong, simple, and works either in λ-calculus or on Pentiums.},
journal = {ACM Trans. Program. Lang. Syst.},
month = sep,
pages = {657–683},
numpages = {27}
}



@article{timany:logical-soundness,
author = {Timany, Amin and Krebbers, Robbert and Dreyer, Derek and Birkedal, Lars},
title = {A Logical Approach to Type Soundness},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {71},
number = {6},
issn = {0004-5411},
url = {https://doi.org/10.1145/3676954},
doi = {10.1145/3676954},
abstract = {Type soundness, which asserts that “well-typed programs cannot go wrong,” is widely viewed as the canonical theorem one must prove to establish that a type system is doing its job. It is commonly proved using the so-called syntactic approach (also known as progress and preservation), which has had a huge impact on the study and teaching of programming language foundations. Unfortunately, syntactic type soundness is a rather weak theorem. It only applies to programs that are well typed in their entirety and thus tells us nothing about the many programs written in “safe” languages that make use of “unsafe” language features. Even worse, it tells us nothing about whether type systems achieve one of their main goals: enforcement of data abstraction. One can easily define a language that enjoys syntactic type soundness and yet fails to support even the most basic modular reasoning principles for abstraction mechanisms like closures, objects, and abstract data types. Given these concerns, we argue that programming languages researchers should no longer be satisfied with proving syntactic type soundness and should instead start proving semantic type soundness, a more useful theorem that captures more accurately what type systems are actually good for. Semantic type soundness is an old idea—Milner’s original account of type soundness from 1978 was semantic—but it fell out of favor in the 1990s due to limitations and complexities of denotational models. In the succeeding decades, thanks to a series of technical advances—notably, step-indexed Kripke logical relations constructed over operational semantics and higher-order concurrent separation logic as consolidated in the Iris framework in Coq—we can now build (machine-checked) semantic soundness proofs at a much higher level of abstraction than was previously possible. The resulting “logical” approach to semantic type soundness has already been employed to great effect in a number of recent papers, but those papers typically (a) concern advanced problem scenarios that complicate the presentation, (b) assume significant prior knowledge of the reader, and (c) suppress many details of the proofs. Here, we aim to provide a gentler, more pedagogically motivated introduction to logical type soundness, targeted at a broader audience that may or may not be familiar with logical relations and Iris. As a bonus, we also show how logical type soundness proofs can easily be generalized to establish an even stronger relational property—representation independence—for realistic type systems.},
journal = {J. ACM},
month = nov,
articleno = {40},
numpages = {75},
keywords = {Type soundness, data abstraction, logical relations, step-indexing, concurrent separation logic, Iris, Coq}
}

@article{LEVY:fgcbv,
title = {Modelling environments in call-by-value programming languages},
journal = {Information and Computation},
volume = {185},
number = {2},
pages = {182-210},
year = {2003},
issn = {0890-5401},
doi = {https://doi.org/10.1016/S0890-5401(03)00088-9},
url = {https://www.sciencedirect.com/science/article/pii/S0890540103000889},
author = {PaulBlain Levy and John Power and Hayo Thielecke},
abstract = {In categorical semantics, there have traditionally been two approaches to modelling environments, one by use of finite products in cartesian closed categories, the other by use of the base categories of indexed categories with structure. Each requires modifications in order to account for environments in call-by-value programming languages. There have been two more general definitions along both of these lines: the first generalising from cartesian to symmetric premonoidal categories, the second generalising from indexed categories with specified structure to κ-categories. In this paper, we investigate environments in call-by-value languages by analysing a fine-grain variant of Moggi’s computational λ-calculus, giving two equivalent sound and complete classes of models: one given by closed Freyd categories, which are based on symmetric premonoidal categories, the other given by closed κ-categories.}
}


@inproceedings{forster:cbpv,
author = {Forster, Yannick and Sch\"{a}fer, Steven and Spies, Simon and Stark, Kathrin},
title = {Call-by-push-value in Coq: operational, equational, and denotational theory},
year = {2019},
isbn = {9781450362221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293880.3294097},
doi = {10.1145/3293880.3294097},
abstract = {Call-by-push-value (CBPV) is an idealised calculus for functional and imperative programming, introduced as a subsuming paradigm for both call-by-value (CBV) and call-by-name (CBN). We formalise weak and strong operational semantics for (effect-free) CBPV, define its equational theory, and verify adequacy for the standard set/algebra denotational semantics. Furthermore, we prove normalisation of the standard reduction, confluence of strong reduction, strong normalisation using Kripke logical relations, and soundness of the equational theory using logical equivalence. We adapt and verify the known translations from CBV and CBN into CBPV for strong reduction. This yields, for instance, proofs of strong normalisation and confluence for the full λ-calculus with sums and products. Thanks to the automation provided by Coq and the Autosubst 2 framework, there is little formalisation overhead compared to detailed paper proofs.},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {118–131},
numpages = {14},
keywords = {type theory, strong normalisation, operational semantics, formalisation, equational theory, denotational semantics, Coq, Call-by-push-value},
location = {Cascais, Portugal},
series = {CPP 2019}
}

@inproceedings{sewell:ott,
author = {Sewell, Peter and Nardelli, Francesco Zappa and Owens, Scott and Peskine, Gilles and Ridge, Thomas and Sarkar, Susmit and Strni\v{s}a, Rok},
title = {Ott: effective tool support for the working semanticist},
year = {2007},
isbn = {9781595938152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291151.1291155},
doi = {10.1145/1291151.1291155},
abstract = {It is rare to give a semantic definition of a full-scale programming language, despite the many potential benefits. Partly this is because the available metalanguages for expressing semantics - usually either L<scp>a</scp>TEX for informal mathematics, or the formal mathematics of a proof assistant - make it much harder than necessary to work with large definitions.We present a metalanguage specifically designed for this problem, and a tool, ott, that sanity-checks such definitions and compiles them into proof assistant code for Coq, HOL, Isabelle, and (in progress) Twelf, together with L<scp>a</scp>TEX code for production-quality typesetting, and OCaml boilerplate. The main innovations are:(1) metalanguage design to make definitions concise, and easy to read and edit;(2) an expressive but intuitive metalanguage for specifying binding structures; and (3) compilation to proof assistant code.This has been tested in substantial case studies, including modular specifications of calculi from the TAPL text, a Lightweight Java with Java JSR 277/294 module system proposals, and a large fragment of OCaml (around 306 rules), with machine proofs of various soundness results. Our aim with this work is to enable a phase change: making it feasible to work routinely, without heroic effort, with rigorous semantic definitions of realistic languages.},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
pages = {1–12},
numpages = {12},
location = {Freiburg, Germany},
series = {ICFP '07}
}



@InProceedings{kahn:natural-semantics,
author="Kahn, G.",
editor="Brandenburg, Franz J.
and Vidal-Naquet, Guy
and Wirsing, Martin",
title="Natural semantics",
booktitle="STACS 87",
year="1987",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="22--39",
abstract="During the past few years, many researchers have begun to present semantic specifications in a style that has been strongly advocated by Plotkin in [19]. The purpose of this paper is to introduce in an intuitive manner the essential ideas of the method that we call now Natural Semantics, together with its connections to ideas in logic and computing. Natural Semantics is of interest per se and because it is used as a semantics specification formalism for an interactive computer system that we are currently building at INRIA.",
isbn="978-3-540-47419-7"
}



@InProceedings{leroy:coinductive-big-step,
author="Leroy, Xavier",
editor="Sestoft, Peter",
title="Coinductive Big-Step Operational Semantics",
booktitle="Programming Languages and Systems",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="54--68",
abstract="This paper illustrates the use of coinductive definitions and proofs in big-step operational semantics, enabling the latter to describe diverging evaluations in addition to terminating evaluations. We show applications to proofs of type soundness and to proofs of semantic preservation for compilers.",
isbn="978-3-540-33096-7"
}



@InProceedings{chargueraud:pretty-big,
author="Chargu{\'e}raud, Arthur",
editor="Felleisen, Matthias
and Gardner, Philippa",
title="Pretty-Big-Step Semantics",
booktitle="Programming Languages and Systems",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="41--60",
abstract="In spite of the popularity of small-step semantics, big-step semantics remain used by many researchers. However, big-step semantics suffer from a serious duplication problem, which appears as soon as the semantics account for exceptions and/or divergence. In particular, many premises need to be copy-pasted across several evaluation rules. This duplication problem, which is particularly visible when scaling up to full-blown languages, results in formal definitions growing far bigger than necessary. Moreover, it leads to unsatisfactory redundancy in proofs. In this paper, we address the problem by introducing pretty-big-step semantics. Pretty-big-step semantics preserve the spirit of big-step semantics, in the sense that terms are directly related to their results, but they eliminate the duplication associated with big-step semantics.",
isbn="978-3-642-37036-6"
}



@phd{mendler:phd,
    author = {Paul Francis Mendler},
    title = {Inductive Definitions in Type Theory},
    institution = {Cornell University}, 
    year = 1987,
    url = { https://nuprl-web.cs.cornell.edu/documents/Mendler/InductiveDefinition.pdf}
}

@article{goedel:systemt,
	author = {Kurt G\"{o}del},
	journal = {Dialectica},
	number = {3},
	pages = {280},
	publisher = {Wiley-Blackwell},
	title = {\"{U}ber Eine Bisher Noch Nicht Ben\"{u}tzte Erweiterung des Finiten Standpunktes},
	volume = {12},
	year = {1958}
}


@article{debruijn:nameless,
title = {Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem},
journal = {Indagationes Mathematicae (Proceedings)},
volume = {75},
number = {5},
pages = {381-392},
year = {1972},
issn = {1385-7258},
doi = {https://doi.org/10.1016/1385-7258(72)90034-0},
url = {https://www.sciencedirect.com/science/article/pii/1385725872900340},
author = {N.G {de Bruijn}},
abstract = {In ordinary lambda calculus the occurrences of a bound variable are made recognizable by the use of one and the same (otherwise irrelevant) name at all occurrences. This convention is known to cause considerable trouble in cases of substitution. In the present paper a different notational system is developed, where occurrences of variables are indicated by integers giving the “distance” to the binding λ instead of a name attached to that λ. The system is claimed to be efficient for automatic formula manipulation as well as for metalingual discussion. As an example the most essential part of a proof of the Church-Rosser theorem is presented in this namefree calculus.}
}

@book{barendregt:lambda-calculus,
	address = {New York, N.Y.},
	author = {Hendrik Pieter Barendregt},
	editor = {},
	publisher = {Sole distributors for the U.S.A. and Canada, Elsevier Science Pub. Co.},
	title = {The Lambda Calculus: Its Syntax and Semantics},
	year = {1984}
}

@book{Pierce:SF2,
    author       =   {Benjamin C. Pierce and
                     Arthur Azevedo de Amorim and
                     Chris Casinghino and
                     Marco Gaboardi and
                     Michael Greenberg and
                     Cătălin Hriţcu and
                     Vilhelm Sjöberg and
                     Andrew Tolmach and
                     Brent Yorgey},
    editor       =   {Benjamin C. Pierce},
    title        =   "Programming Language Foundations",
    series       =   "Software Foundations",
    volume       =   "2",
    year         =   "2025",
    publisher    =   "Electronic textbook",
    note         =   {Version 6.7,
                      \url{http://softwarefoundations.cis.upenn.edu} },
    }


@book{harper:pfpl,
author = {Harper, Robert},
title = {Practical Foundations for Programming Languages},
year = {2016},
isbn = {1107150302},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {This text develops a comprehensive theory of programming languages based on type systems and structural operational semantics. Language concepts are precisely defined by their static and dynamic semantics, presenting the essential tools both intuitively and rigorously while relying on only elementary mathematics. These tools are used to analyze and prove properties of languages and provide the framework for combining and comparing language features. The broad range of concepts includes fundamental data types such as sums and products, polymorphic and abstract types, dynamic typing, dynamic dispatch, subtyping and refinement types, symbols and dynamic classification, parallelism and cost semantics, and concurrency and distribution. The methods are directly applicable to language implementation, to the development of logics for reasoning about programs, and to the formal verification language properties such as type safety. This thoroughly revised second edition includes exercises at the end of nearly every chapter and a new chapter on type refinements.}
}

@book{pierce:tapl,
  author = {Benjamin C. Pierce},
  title = {Types and Programming Languages},
  publisher = {MIT Press},
  year = 2002,
  plclub = {Yes},
  bcp = {Yes},
  keys = {books},
  homepage = {http://www.cis.upenn.edu/~bcpierce/tapl},
  errata = {http://www.cis.upenn.edu/~bcpierce/tapl/errata.txt}
}



@article{wright:syntactic,
title = {A Syntactic Approach to Type Soundness},
journal = {Information and Computation},
volume = {115},
number = {1},
pages = {38-94},
year = {1994},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1994.1093},
url = {https://www.sciencedirect.com/science/article/pii/S0890540184710935},
author = {A.K. Wright and M. Felleisen},
abstract = {We present a new approach to proving type soundness for Hindley/Milner-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the technique with a type soundness theorem for the core of Standard ML, which includes the first type soundness proof for polymorphic exceptions and continuations.}
}

@article{milner:polymorphism,
title = {A theory of type polymorphism in programming},
journal = {Journal of Computer and System Sciences},
volume = {17},
number = {3},
pages = {348-375},
year = {1978},
issn = {0022-0000},
doi = {https://doi.org/10.1016/0022-0000(78)90014-4},
url = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
author = {Robin Milner},
abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.}
}
